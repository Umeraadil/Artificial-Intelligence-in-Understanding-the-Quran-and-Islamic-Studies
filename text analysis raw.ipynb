{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import nltk\nimport string\nfrom wordcloud import WordCloud\nimport matplotlib.pyplot as plt\nfrom collections import Counter","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"../input/the-holy-quran/English.csv\", header = None, encoding = \"ISO-8859-1\")\n#Data Snapshot\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Create Surah & Ayat Index\ndf1 = df[0].str.split(\"|\", expand = True)\ndf1.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Connect Surah & Ayat to orginal\ndf2 = pd.concat([df1,df.iloc[:,1:]], axis = 1)\ndf2.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Combine Columns 2:16 in one\ndf_a = pd.DataFrame()\nfor a,b in df2.iterrows():\n    load = b[2:]    \n    data = ''\n    for aa in load:\n        if str(aa) != 'nan':\n            data += str(aa)\n    df_a = df_a.append([data])\n    \ndf_a","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df3 = pd.concat([df2.iloc[:,:2],df_a.reset_index().rename(columns = {0:\"Data\"})], axis = 1).drop(columns = 'index').rename(columns = {0:\"Surah\",1:'Ayat'})\n\ndf3","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"surahs = df3['Surah'].unique().tolist()\n\nSurah_Data = []\nfor surah in surahs:\n    Data = ''\n    for val in df3[df3[\"Surah\"] == surah]['Data']:\n        Data += val\n    Surah_Data.append(Data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Surahs_df = pd.DataFrame({'Data':Surah_Data}).reset_index().rename(columns = {'index':\"Surah\"})\nSurahs_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Surahs_df[\"Data\"]=Surahs_df[\"Data\"].str.replace(';',' ')\nSurahs_df[\"Data\"]=Surahs_df[\"Data\"].str.replace('.',' ')\nSurahs_df[\"Data\"]=Surahs_df[\"Data\"].str.replace(':','')\nSurahs_df[\"Data\"]=Surahs_df[\"Data\"].str.replace('(','')\nSurahs_df[\"Data\"]=Surahs_df[\"Data\"].str.replace('\"','')\nSurahs_df[\"Data\"]=Surahs_df[\"Data\"].str.replace(')','')\nSurahs_df[\"Data\"]=Surahs_df[\"Data\"].str.replace('-','')\nSurahs_df[\"Data\"]=Surahs_df[\"Data\"].str.replace('Qur´an','Quran')\nSurahs_df[\"Data\"]=Surahs_df[\"Data\"].str.replace('Allah´s',\"Allah's\")\nSurahs_df[\"Data\"]=Surahs_df[\"Data\"].str.replace('Isma´il',\"Ismail\")\nSurahs_df[\"Data\"]=Surahs_df[\"Data\"].str.replace('Shu´aib',\"Shuaib\")\nSurahs_df[\"Data\"]=Surahs_df[\"Data\"].str.replace('´partners´',\"partners\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nltk.download(\"stopwords\")\nnltk.download(\"punkt\")\n#Create Stop Words Corpus\nstop_words = nltk.corpus.stopwords.words(\"english\") + list(string.punctuation) \\\n+ list(string.ascii_lowercase) + list(string.ascii_uppercase) + list(string.digits) \\\n+ list(['--']+[\"''\"]+[\"``\"]+[\"..\"]+[\"...\"]+[\"ii\"]+[\"iii\"]+[\"iv\"]+[\"'s\"]+[\"the\"]+[\"however\"] \\\n+ [\"when\"]+[\"as\"]+[\"meanwhile\"]+['eventually'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Surah = 1\nData = ''\nfor a in Surahs_df['Data']:\n    Data += a\ntokens = nltk.word_tokenize(Data)\n\n# Convert the tokens into lowercase: lower_tokens\nlower_tokens = [s.lower() for s in tokens]\n\nfiltered_sentence  = [w for w in lower_tokens if not w in stop_words]\n\n#Count Words\nhr1_counter = Counter(filtered_sentence)\n#Sort Words by counts\nsorted_word_counts = sorted(list(hr1_counter.values()), reverse=True)\nprint(hr1_counter.most_common(50))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Data_1 = Data.split(' ')\n\nbad_words = {}\nbad_words[Data_1[0]] = 1\n\ncount = 0\nfor a in tokens:\n    if a.isalpha() == False:\n        if a in bad_words.keys():\n            bad_words[a] += 1\n        else:\n            bad_words[a] = 1\n        count+=1\nbad_df = pd.DataFrame.from_dict(\n    bad_words,orient='index').reset_index()\nbad_df.sort_values(0,ascending = False).head(30)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_vocab = pd.DataFrame.from_dict(hr1_counter,orient = 'index').reset_index().rename(columns = {'index':'Vocab',0:'Count'})\ndf_vocab.sort_values('Count',ascending = False).head(15)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Surah = 1\nData = ''\nfor a in Surahs_df['Data']:\n    Data += a\ntokens = nltk.word_tokenize(Data)\n\n# Convert the tokens into lowercase: lower_tokens\nlower_tokens = [s.lower() for s in tokens]\n\nhr1_filter = [w for w in lower_tokens if not w in stop_words]\n#Count Words\nhr1_counter = Counter(hr1_filter)\n#Sort Words by counts\nsorted_word_counts = sorted(list(hr1_counter.values()), reverse=True)\nprint(hr1_counter.most_common(50))\n    \n#Set Width & Height\nwidth = 12\nheight = 12\n#Initialize Plot\nplt.figure(figsize=(width, height))\n#Generate Wordplot\nwordcloud = WordCloud(width=1800,height=1400).generate(str(hr1_filter))\nplt.imshow(wordcloud)\nplt.axis(\"off\")\n#Generate Plot\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.6.15","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":5}